{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83932e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics>=8.3.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (8.3.210)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (11.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.7.0)\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (3.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (0.23.0+cu126)\n",
      "Requirement already satisfied: psutil in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (7.0.0)\n",
      "Requirement already satisfied: polars in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (1.34.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from ultralytics>=8.3.0) (2.0.17)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from albumentations) (2.11.7)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Using cached albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from albucore==0.0.24->albumentations) (4.2.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics>=8.3.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics>=8.3.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics>=8.3.0) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics>=8.3.0) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics>=8.3.0) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics>=8.3.0) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib>=3.3.0->ultralytics>=8.3.0) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic>=2.9.2->albumentations) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics>=8.3.0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.23.0->ultralytics>=8.3.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.23.0->ultralytics>=8.3.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.23.0->ultralytics>=8.3.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.23.0->ultralytics>=8.3.0) (2025.6.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.8.0->ultralytics>=8.3.0) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.8.0->ultralytics>=8.3.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.8.0->ultralytics>=8.3.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.8.0->ultralytics>=8.3.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.8.0->ultralytics>=8.3.0) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch>=1.8.0->ultralytics>=8.3.0) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics>=8.3.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->torch>=1.8.0->ultralytics>=8.3.0) (3.0.2)\n",
      "Requirement already satisfied: polars-runtime-32==1.34.0 in c:\\users\\armaa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from polars->ultralytics>=8.3.0) (1.34.0)\n",
      "Using cached albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Using cached albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Using cached opencv_python_headless-4.12.0.88-cp37-abi3-win_amd64.whl (38.9 MB)\n",
      "Installing collected packages: opencv-python-headless, albucore, albumentations\n",
      "\n",
      "   ---------------------------------------- 0/3 [opencv-python-headless]\n",
      "   ---------------------------------------- 0/3 [opencv-python-headless]\n",
      "   ------------- -------------------------- 1/3 [albucore]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   -------------------------- ------------- 2/3 [albumentations]\n",
      "   ---------------------------------------- 3/3 [albumentations]\n",
      "\n",
      "Successfully installed albucore-0.0.24 albumentations-2.0.8 opencv-python-headless-4.12.0.88\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If needed\n",
    "# %pip install --upgrade pip\n",
    "%pip install \"ultralytics>=8.3.0\" opencv-python pillow scikit-learn albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd48c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, shutil, random, math, time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "RAW_DATA = ROOT / \"data\"             # 4 class folders live here\n",
    "YOLO_ROOT = ROOT / \"yolo_data\"\n",
    "IM_TRAIN = YOLO_ROOT / \"images\" / \"train\"\n",
    "IM_VAL   = YOLO_ROOT / \"images\" / \"val\"\n",
    "LB_TRAIN = YOLO_ROOT / \"labels\" / \"train\"\n",
    "LB_VAL   = YOLO_ROOT / \"labels\" / \"val\"\n",
    "YOLO_YAML = YOLO_ROOT / \"data.yaml\"\n",
    "\n",
    "# Split + augmentation\n",
    "VAL_SPLIT = 0.15\n",
    "AUG_MULTIPLIER = 5            # generate 5 augmented variants per original train image\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED); np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Center check for live\n",
    "CENTER_BOX_FRAC = 0.30\n",
    "\n",
    "# Training\n",
    "MODEL_NAME = \"yolov8n.pt\"\n",
    "IMG_SIZE   = 416\n",
    "EPOCHS     = 40\n",
    "BATCH      = 2\n",
    "WORKERS    = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02063c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Capacitor', 'IC', 'Processor', 'Tan_Cap']\n",
      "Found 414 images total\n"
     ]
    }
   ],
   "source": [
    "# classes = folder names (exactly the 4 you care about)\n",
    "class_names = sorted([d.name for d in RAW_DATA.iterdir() if d.is_dir()])\n",
    "assert len(class_names) == 4, f\"Expected 4 classes, found {len(class_names)}: {class_names}\"\n",
    "class_to_idx = {c:i for i,c in enumerate(class_names)}\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "VALID_EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\"}\n",
    "\n",
    "def list_images():\n",
    "    items = []\n",
    "    for cls in class_names:\n",
    "        for p in (RAW_DATA/cls).rglob(\"*\"):\n",
    "            if p.suffix.lower() in VALID_EXTS:\n",
    "                items.append((p, class_to_idx[cls]))\n",
    "    return items\n",
    "\n",
    "all_items = list_images()\n",
    "assert len(all_items) > 0, \"No images found under ./data/<class> folders.\"\n",
    "print(f\"Found {len(all_items)} images total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a339154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rgb(path):\n",
    "    try:\n",
    "        im = Image.open(path).convert(\"RGB\")\n",
    "        return np.array(im)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] Unreadable: {path} ({e})\")\n",
    "        return None\n",
    "\n",
    "def find_largest_box(img):\n",
    "    \"\"\"\n",
    "    Returns (x1,y1,x2,y2) for the main object, or None if nothing decent.\n",
    "    Stronger than simple edges: adaptive threshold + morphology + filters.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY_INV, 31, 5)\n",
    "    k = np.ones((3,3), np.uint8)\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_OPEN, k, iterations=1)\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, k, iterations=2)\n",
    "\n",
    "    cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts: return None\n",
    "\n",
    "    area_min = 0.02 * (w*h)  # ignore <2% area\n",
    "    cands = []\n",
    "    for c in cnts:\n",
    "        x,y,ww,hh = cv2.boundingRect(c)\n",
    "        area = ww*hh\n",
    "        if area < area_min: \n",
    "            continue\n",
    "        ar = ww / max(1, hh)\n",
    "        if ar < 0.2 or ar > 5.0: \n",
    "            continue\n",
    "        cands.append((x,y,x+ww,y+hh, area))\n",
    "    if not cands: \n",
    "        return None\n",
    "\n",
    "    x1,y1,x2,y2,_ = max(cands, key=lambda t:t[4])\n",
    "    # slight padding\n",
    "    px, py = int(0.02*w), int(0.02*h)\n",
    "    x1 = max(0, x1-px); y1 = max(0, y1-py)\n",
    "    x2 = min(w-1, x2+px); y2 = min(h-1, y2+py)\n",
    "    return (x1,y1,x2,y2)\n",
    "\n",
    "def yolo_line_from_box(cls_id, box, w, h):\n",
    "    x1,y1,x2,y2 = box\n",
    "    bw = x2-x1; bh = y2-y1\n",
    "    cx = x1 + bw/2; cy = y1 + bh/2\n",
    "    return f\"{cls_id} {cx/w:.6f} {cy/h:.6f} {bw/w:.6f} {bh/h:.6f}\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d929128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 351 | Val: 63\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu_253658-1870 (3).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu_253658-1870 (3).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-microprocessor-cpu-close-up-isolated-white-backgrou.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-microprocessor-cpu-close-up-isolated-white-backgrou.jpg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\armaa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\PIL\\Image.py:3570: UserWarning: image file could not be identified because AVIF support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\single-microchip-isolated-white-background_941600-88404(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\single-microchip-isolated-white-background_941600-88404(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\high-angle-view-computer-chip-against-white-background_10489 (1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\high-angle-view-computer-chip-against-white-background_10489 (1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\single-microchip-isolated-white-background_941600-88404.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\single-microchip-isolated-white-background_941600-88404.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-microprocessor-cpu-close-up-isolated-white-backgrou(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-microprocessor-cpu-close-up-isolated-white-backgrou(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\central-processing-unit-computer-chip_41929-1449.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\central-processing-unit-computer-chip_41929-1449.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\directly-computer-chip-against-white-background_1048944-2255(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\directly-computer-chip-against-white-background_1048944-2255(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu-central-processing-unit-microchip-isolated-white-backgro.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu-central-processing-unit-microchip-isolated-white-backgro.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-processor-cpu-white-background_627429-130.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-processor-cpu-white-background_627429-130.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-cpu-png-mockup-closeup_53876-1021502 (1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-cpu-png-mockup-closeup_53876-1021502 (1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\directly-computer-chip-against-white-background_1048944-2255.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\directly-computer-chip-against-white-background_1048944-2255.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-processors-cpu_1155277-2155.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-processors-cpu_1155277-2155.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-microprocessor-cpu-close-up-isolated-white-backgrou (3).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-microprocessor-cpu-close-up-isolated-white-backgrou (3).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu_253658-1870.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu_253658-1870.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\central-processor-unit-cpu-chip-blue-monochrome-toned-white-.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\central-processor-unit-cpu-chip-blue-monochrome-toned-white-.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu-processor-chip-isolated-white-background_1048944-1362788.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu-processor-chip-isolated-white-background_1048944-1362788.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\high-angle-view-information-sign-against-white-background_10.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\high-angle-view-information-sign-against-white-background_10.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-cpu-png-mockup-closeup_53876-1021502(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-cpu-png-mockup-closeup_53876-1021502(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu_253658-720(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu_253658-720(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu-central-processor-unit-isolated-background_77829-3621.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu-central-processor-unit-isolated-background_77829-3621.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-processor-cpu-central-processing-unit-microchip-iso (2).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-processor-cpu-central-processing-unit-microchip-iso (2).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\lowpower-microprocessor-portable-computers-isolated_1120557-(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\lowpower-microprocessor-portable-computers-isolated_1120557-(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\central-computer-processors-cpu-high-resolution-3d-render-wh (1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\central-computer-processors-cpu-high-resolution-3d-render-wh (1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\close-up-yellow-pencil-white-background_1048944-22361352.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\close-up-yellow-pencil-white-background_1048944-22361352.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\lowpower-microprocessor-portable-computers-isolated_1120557-.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\lowpower-microprocessor-portable-computers-isolated_1120557-.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\high-angle-view-computer-chip-against-white-background_10489(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\high-angle-view-computer-chip-against-white-background_10489(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-processor_769373-2529.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-processor_769373-2529.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu-central-processor-unit-isolated_77829-4075.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu-central-processor-unit-isolated_77829-4075.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\intel-processor-shines-sleek-white-background-captivating-ph.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\intel-processor-shines-sleek-white-background-captivating-ph.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu_253658-1870(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu_253658-1870(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\high-angle-view-information-sign-against-white-background_10(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\high-angle-view-information-sign-against-white-background_10(1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu_253658-720 (1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu_253658-720 (1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-engineering-microprocessor-processor-isolated-white.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-engineering-microprocessor-processor-isolated-white.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu-central-processor-unit-isolated_77829-4020.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu-central-processor-unit-isolated_77829-4020.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-cpu-processor-closeup-visible-gold-pins-isolated-wh.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-cpu-processor-closeup-visible-gold-pins-isolated-wh.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu-processor-chip-isolated-white-background_1048944-2976349.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu-processor-chip-isolated-white-background_1048944-2976349.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\close-up-yellow-pencil-white-background_1048944-22361352(1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\close-up-yellow-pencil-white-background_1048944-22361352(1).jpg')\n",
      "Wrote 313 base images + labels -> d:\\Coding\\Projects\\Classifier\\yolo_data\\images\\train\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-micro-processor_769373-2527.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-micro-processor_769373-2527.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\electronic-collection-computer-processor-from-top-side-isola.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\electronic-collection-computer-processor-from-top-side-isola.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-processor-cpu-central-processing-unit-microchip-iso.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-processor-cpu-central-processing-unit-microchip-iso.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu-central-processor-unit-isolated_77829-4729.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu-central-processor-unit-isolated_77829-4729.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\high-angle-view-computer-chip-against-white-background_10489.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\high-angle-view-computer-chip-against-white-background_10489.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\high-angle-view-information-sign-against-white-background_10 (1).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\high-angle-view-information-sign-against-white-background_10 (1).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-cpu-png-mockup-closeup_53876-1021502.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-cpu-png-mockup-closeup_53876-1021502.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\close-up-yellow-pencil-white-background_1048944-22361352 (3).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\close-up-yellow-pencil-white-background_1048944-22361352 (3).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\directly-computer-chip-against-white-background_1048944-2255 (5).jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\directly-computer-chip-against-white-background_1048944-2255 (5).jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\computer-microchip-electronic-microcircuit_99433-5234.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\computer-microchip-electronic-microcircuit_99433-5234.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu-central-processor-unit_996086-23712.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu-central-processor-unit_996086-23712.jpg')\n",
      "[skip] Unreadable: d:\\Coding\\Projects\\Classifier\\data\\Processor\\cpu_253658-720.jpg (cannot identify image file 'd:\\\\Coding\\\\Projects\\\\Classifier\\\\data\\\\Processor\\\\cpu_253658-720.jpg')\n",
      "Wrote 51 base images + labels -> d:\\Coding\\Projects\\Classifier\\yolo_data\\images\\val\n"
     ]
    }
   ],
   "source": [
    "# Split indices\n",
    "y = [cid for _, cid in all_items]\n",
    "idx = np.arange(len(all_items))\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_SPLIT, random_state=RANDOM_SEED)\n",
    "train_idx, val_idx = next(sss.split(idx, y))\n",
    "train_items = [all_items[i] for i in train_idx]\n",
    "val_items   = [all_items[i] for i in val_idx]\n",
    "print(f\"Train: {len(train_items)} | Val: {len(val_items)}\")\n",
    "\n",
    "# Reset folders\n",
    "if YOLO_ROOT.exists(): shutil.rmtree(YOLO_ROOT)\n",
    "IM_TRAIN.mkdir(parents=True, exist_ok=True); IM_VAL.mkdir(parents=True, exist_ok=True)\n",
    "LB_TRAIN.mkdir(parents=True, exist_ok=True); LB_VAL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def write_split(items, im_dst, lb_dst):\n",
    "    kept = 0\n",
    "    for src_path, cls_id in items:\n",
    "        img = load_rgb(src_path)\n",
    "        if img is None: continue\n",
    "        h, w = img.shape[:2]\n",
    "        box = find_largest_box(img)\n",
    "        if box is None:\n",
    "            # fallback: centered box (medium size)\n",
    "            bw, bh = int(0.5*w), int(0.5*h)\n",
    "            x1 = (w-bw)//2; y1 = (h-bh)//2\n",
    "            box = (x1,y1,x1+bw,y1+bh)\n",
    "\n",
    "        out_img = im_dst / src_path.name\n",
    "        Image.fromarray(img).save(out_img)\n",
    "\n",
    "        yolo_line = yolo_line_from_box(cls_id, box, w, h)\n",
    "        (lb_dst / (out_img.stem + \".txt\")).write_text(yolo_line)\n",
    "        kept += 1\n",
    "    print(f\"Wrote {kept} base images + labels -> {im_dst}\")\n",
    "\n",
    "write_split(train_items, IM_TRAIN, LB_TRAIN)\n",
    "write_split(val_items,   IM_VAL,   LB_VAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c48182",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '3.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 112\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAugmented images written: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# Rebuild augmented training set\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[43maugment_train_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAUG_MULTIPLIER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# (optional) quick count check\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain images:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m([p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m IM_TRAIN.iterdir() \u001b[38;5;28;01mif\u001b[39;00m p.suffix.lower() \u001b[38;5;129;01min\u001b[39;00m VALID_EXTS]))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36maugment_train_set\u001b[39m\u001b[34m(mult)\u001b[39m\n\u001b[32m     68\u001b[39m class_labels = []\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ln \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     c = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mln\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m; cx, cy, bw, bh = \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, ln[\u001b[32m1\u001b[39m:\u001b[32m5\u001b[39m])\n\u001b[32m     71\u001b[39m     x1, y1, x2, y2 = yolo_to_voc_px(cx, cy, bw, bh, w, h)\n\u001b[32m     72\u001b[39m     bboxes_voc.append([x1, y1, x2, y2]); class_labels.append(c)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: '3.0'"
     ]
    }
   ],
   "source": [
    "# ===== Stable, version-agnostic bbox augmentation =====\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "# Safer ops only (no RandomResizedCrop / Sharpen version drama)\n",
    "AUG_PIPE = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.6),\n",
    "    A.HueSaturationValue(hue_shift_limit=8, sat_shift_limit=20, val_shift_limit=15, p=0.4),\n",
    "    A.GaussNoise(var_limit=(5.0, 25.0), p=0.2),\n",
    "    A.MotionBlur(blur_limit=5, p=0.2),\n",
    "    A.Affine(scale=(0.85, 1.15), translate_percent=(0.0, 0.05), rotate=(-10, 10),\n",
    "             shear=(-5, 5), mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
    "    # Resize last to your training size\n",
    "    A.Resize(height=int(IMG_SIZE), width=int(IMG_SIZE), interpolation=cv2.INTER_LINEAR),\n",
    "], bbox_params=A.BboxParams(\n",
    "    format=\"pascal_voc\",\n",
    "    label_fields=[\"class_labels\"],\n",
    "    min_visibility=0.4\n",
    "))\n",
    "\n",
    "def yolo_to_voc_px(cx, cy, bw, bh, w, h):\n",
    "    x1 = (cx - bw/2) * w\n",
    "    y1 = (cy - bh/2) * h\n",
    "    x2 = (cx + bw/2) * w\n",
    "    y2 = (cy + bh/2) * h\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def voc_px_to_yolo(x1, y1, x2, y2, w, h):\n",
    "    bw = max(1.0, x2 - x1); bh = max(1.0, y2 - y1)  # ≥1px\n",
    "    cx = x1 + bw/2; cy = y1 + bh/2\n",
    "    return [cx / w, cy / h, bw / w, bh / h]\n",
    "\n",
    "def clamp_voc(x1, y1, x2, y2, w, h):\n",
    "    # clamp to [0, w-1]/[0,h-1] and fix order\n",
    "    x1 = max(0.0, min(float(w - 1), x1))\n",
    "    y1 = max(0.0, min(float(h - 1), y1))\n",
    "    x2 = max(0.0, min(float(w - 1), x2))\n",
    "    y2 = max(0.0, min(float(h - 1), y2))\n",
    "    if x2 <= x1: x2 = min(w - 1.0, x1 + 1.0)\n",
    "    if y2 <= y1: y2 = min(h - 1.0, y1 + 1.0)\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def augment_train_set(mult=AUG_MULTIPLIER):\n",
    "    ims = sorted([p for p in IM_TRAIN.iterdir() if p.suffix.lower() in VALID_EXTS])\n",
    "    count = 0\n",
    "    for p in ims:\n",
    "        lbp = LB_TRAIN / (p.stem + \".txt\")\n",
    "        if not lbp.exists():\n",
    "            continue\n",
    "\n",
    "        img_bgr = cv2.imread(str(p))\n",
    "        if img_bgr is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # read YOLO -> VOC(px)\n",
    "        lines = [ln.strip().split() for ln in lbp.read_text().strip().splitlines() if ln.strip()]\n",
    "        if not lines:\n",
    "            continue\n",
    "        bboxes_voc = []\n",
    "        class_labels = []\n",
    "        for ln in lines:\n",
    "            c = int(ln[0]); cx, cy, bw, bh = map(float, ln[1:5])\n",
    "            x1, y1, x2, y2 = yolo_to_voc_px(cx, cy, bw, bh, w, h)\n",
    "            bboxes_voc.append([x1, y1, x2, y2]); class_labels.append(c)\n",
    "\n",
    "        for k in range(mult):\n",
    "            # robust to random failures\n",
    "            try:\n",
    "                t = AUG_PIPE(image=img, bboxes=bboxes_voc, class_labels=class_labels)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            im2 = t[\"image\"]; bb2 = t[\"bboxes\"]; cl2 = t[\"class_labels\"]\n",
    "            if len(bb2) == 0:\n",
    "                continue\n",
    "\n",
    "            h2, w2 = im2.shape[:2]\n",
    "            filtered = []\n",
    "            for (x1, y1, x2, y2), c in zip(bb2, cl2):\n",
    "                x1, y1, x2, y2 = clamp_voc(x1, y1, x2, y2, w2, h2)\n",
    "                bw = x2 - x1; bh = y2 - y1\n",
    "                if bw * bh < 4:  # tiny → drop\n",
    "                    continue\n",
    "                filtered.append((c, x1, y1, x2, y2))\n",
    "            if not filtered:\n",
    "                continue\n",
    "\n",
    "            out_img = IM_TRAIN / f\"{p.stem}_aug{k}.jpg\"\n",
    "            cv2.imwrite(str(out_img), cv2.cvtColor(im2, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            with open(LB_TRAIN / f\"{p.stem}_aug{k}.txt\", \"w\") as f:\n",
    "                for c, x1, y1, x2, y2 in filtered:\n",
    "                    cx, cy, bw, bh = voc_px_to_yolo(x1, y1, x2, y2, w2, h2)\n",
    "                    # final clamp\n",
    "                    cx = min(1.0, max(0.0, cx)); cy = min(1.0, max(0.0, cy))\n",
    "                    bw = min(1.0, max(1e-6, bw)); bh = min(1.0, max(1e-6, bh))\n",
    "                    f.write(f\"{c} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "            count += 1\n",
    "    print(f\"Augmented images written: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "with open(YOLO_YAML, \"w\") as f:\n",
    "    f.write(f\"path: {str(YOLO_ROOT)}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\")\n",
    "    f.write(\"names:\\n\")\n",
    "    for i,n in enumerate(class_names):\n",
    "        f.write(f\"  {i}: {n}\\n\")\n",
    "\n",
    "print(YOLO_YAML.read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cbabff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(MODEL_NAME)  # pretrained nano\n",
    "results = model.train(\n",
    "    data=str(YOLO_YAML),\n",
    "    device=\"cpu\",          # ← keep CPU for stability; change to 0 for GPU later\n",
    "    imgsz=IMG_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH,\n",
    "    workers=WORKERS,\n",
    "    amp=False,\n",
    "    mosaic=0.0,\n",
    "    cache=False,\n",
    "    freeze=0,              # let backbone adapt (we augmented)\n",
    "    patience=10,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "best_path = getattr(model, \"ckpt_path\", None) or getattr(model.trainer, \"best\", None)\n",
    "print(\"Best model:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6da71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(best_path)\n",
    "val_res = model.val(data=str(YOLO_YAML), imgsz=IMG_SIZE, device=\"cpu\")\n",
    "print(f\"mAP50-95: {val_res.box.map:.4f} | mAP50: {val_res.box.map50:.4f}\")\n",
    "for i, n in enumerate(class_names):\n",
    "    print(f\"{n}: AP50-95={val_res.box.maps[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_centered(box_xyxy, frame_w, frame_h, frac=CENTER_BOX_FRAC):\n",
    "    x1,y1,x2,y2 = box_xyxy\n",
    "    cx = 0.5*(x1+x2); cy = 0.5*(y1+y2)\n",
    "    fx = frame_w*0.5; fy = frame_h*0.5\n",
    "    hw = frame_w*frac*0.5; hh = frame_h*frac*0.5\n",
    "    return (fx-hw) <= cx <= (fx+hw) and (fy-hh) <= cy <= (fy+hh)\n",
    "\n",
    "def predict_image(path, conf_th=0.10):\n",
    "    mdl = YOLO(best_path if 'best_path' in globals() and best_path else MODEL_NAME)\n",
    "    res = mdl.predict(source=path, imgsz=IMG_SIZE, conf=conf_th, verbose=False, device=\"cpu\")\n",
    "    for r in res:\n",
    "        if r.boxes is None or len(r.boxes)==0:\n",
    "            print(\"No detections.\")\n",
    "            continue\n",
    "        for b in r.boxes:\n",
    "            cid = int(b.cls.item()); conf = float(b.conf.item())\n",
    "            xyxy = list(map(int, b.xyxy.squeeze().cpu().numpy().tolist()))\n",
    "            print(f\"{class_names[cid]} @ {conf:.2f} -> {xyxy}\")\n",
    "        r.show()  # view overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_video_classify(cam_index=0, conf_th=0.15):\n",
    "    from collections import deque\n",
    "    mdl = YOLO(best_path if 'best_path' in globals() and best_path else MODEL_NAME)\n",
    "\n",
    "    cap = cv2.VideoCapture(cam_index)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Could not open webcam.\"); return\n",
    "\n",
    "    history = deque(maxlen=5)\n",
    "    try:\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok: break\n",
    "            h, w = frame.shape[:2]\n",
    "\n",
    "            res = mdl.predict(source=frame, imgsz=IMG_SIZE, conf=conf_th, verbose=False, device=\"cpu\")\n",
    "            preds = []\n",
    "            for r in res:\n",
    "                if r.boxes is None: continue\n",
    "                for b in r.boxes:\n",
    "                    cid = int(b.cls.item()); conf = float(b.conf.item())\n",
    "                    xyxy = b.xyxy.squeeze().cpu().numpy().tolist()\n",
    "                    preds.append((cid, conf, xyxy))\n",
    "\n",
    "            # center window\n",
    "            fx, fy = int(w*0.5), int(h*0.5)\n",
    "            hw, hh = int(w*CENTER_BOX_FRAC*0.5), int(h*CENTER_BOX_FRAC*0.5)\n",
    "            cv2.rectangle(frame, (fx-hw, fy-hh), (fx+hw, fy+hh), (128,128,128), 1)\n",
    "\n",
    "            any_yes = False\n",
    "            for (cid, conf, xyxy) in preds:\n",
    "                x1,y1,x2,y2 = map(int, xyxy)\n",
    "                centered = is_centered(xyxy, w, h, frac=CENTER_BOX_FRAC)\n",
    "                any_yes |= centered\n",
    "                color = (0,255,0) if centered else (0,165,255)\n",
    "                cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n",
    "                label = f\"{class_names[cid]} {conf:.2f}\"\n",
    "                cv2.putText(frame, label, (x1, max(20,y1-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            history.append(1 if any_yes else 0)\n",
    "            stable_yes = sum(history) >= 3\n",
    "            status = \"YES\" if stable_yes else \"NO\"\n",
    "            cv2.putText(frame, status, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                        (0,255,0) if stable_yes else (0,0,255), 2)\n",
    "\n",
    "            cv2.imshow(\"Live Detection (q to quit)\", frame)\n",
    "            if (cv2.waitKey(1) & 0xFF) == ord('q'): break\n",
    "    finally:\n",
    "        cap.release(); cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(path, conf_th=0.25):\n",
    "    mdl = YOLO(best_path if 'best_path' in globals() else MODEL_NAME)\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    res = mdl.predict(source=im, imgsz=IMG_SIZE, conf=conf_th, verbose=False)\n",
    "    for r in res:\n",
    "        r.show()  # opens a window with predictions\n",
    "\n",
    "predict_image(\"test/im9.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52ae90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
